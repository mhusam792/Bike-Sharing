{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "302130b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "786cf481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4           1  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/raw/hour.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb69376e",
   "metadata": {},
   "source": [
    "## 1- Data Understanding\n",
    "- What are the columns in the data? Explain each column.\n",
    "- What columns contain missing values? And how do you intend to deal with them?\n",
    "- Are there any columns that need conversion or re-encoding?\n",
    "- Will the target column be CNT, registered, casual, and why did you choose this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849fbaed",
   "metadata": {},
   "source": [
    "### Dataset characteristics\n",
    "\n",
    "Both hour.csv and day.csv have the following fields, except hr which is not available in day.csv\n",
    "\t\n",
    "\t- instant: record index\n",
    "\t- dteday : date\n",
    "\t- season : season (1:springer, 2:summer, 3:fall, 4:winter)\n",
    "\t- yr : year (0: 2011, 1:2012)\n",
    "\t- mnth : month ( 1 to 12)\n",
    "\t- hr : hour (0 to 23)\n",
    "\t- holiday : weather day is holiday or not (extracted from http://dchr.dc.gov/page/holiday-schedule)\n",
    "\t- weekday : day of the week\n",
    "\t- workingday : if day is neither weekend nor holiday is 1, otherwise is 0.\n",
    "\t+ weathersit : \n",
    "\t\t- 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "\t\t- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "\t\t- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "\t\t- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
    "\t- temp : Normalized temperature in Celsius. The values are divided to 41 (max)\n",
    "\t- atemp: Normalized feeling temperature in Celsius. The values are divided to 50 (max)\n",
    "\t- hum: Normalized humidity. The values are divided to 100 (max)\n",
    "\t- windspeed: Normalized wind speed. The values are divided to 67 (max)\n",
    "\t- casual: count of casual users\n",
    "\t- registered: count of registered users\n",
    "\t- cnt: count of total rental bikes including both casual and registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fd40ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns with NA values\n",
    "na_cols = [col for col in df.columns if df[col].isna().sum() > 0 ]\n",
    "print(f\"Columns with Null values: {na_cols}\")\n",
    "\n",
    "\n",
    "# Is there any columns that need any transformation or encoding?\n",
    "SEASON = {1:'spring', 2:'summer', 3:'fall', 4:'winter'} # Mapping this dict with dataframe for getting insights\n",
    "WEATHERSIT = {1:'clear', 2:'mist', 3:'light snow', 4:'heavy rain'} # Mapping this dict with dataframe for getting insights\n",
    "NORMALIZE = {'temp':41, 'atemp':50, 'hum':100, 'windspeed':67} # Undo Normalize for getting real values, Before normalize\n",
    "WORKDAY_OR_HOLIDAY = {0:'holiday', 1:'workday'}\n",
    "\n",
    "def real_values(df):\n",
    "    df = df.copy()\n",
    "    for col, max_val in NORMALIZE.items():\n",
    "        df[f\"real_{col}\"] = df[col] * max_val\n",
    "    return df\n",
    "\n",
    "df = real_values(df=df)\n",
    "\n",
    "# Converting dtype to datetime type\n",
    "df.dteday = pd.to_datetime(df.dteday, format='%Y-%m-%d')\n",
    "\n",
    "# Getting real values\n",
    "df['real_season'] = df.season.map(SEASON)\n",
    "df['real_weathersit'] = df.weathersit.map(WEATHERSIT)\n",
    "df['weekday_name'] = df.dteday.dt.day_name()\n",
    "df['month_name'] = df.dteday.dt.month_name().str.slice(start=0, stop=3)\n",
    "df['workday_or_holiday'] = df.workingday.map(WORKDAY_OR_HOLIDAY)\n",
    "\n",
    "# Which feature I will select to be the target feature?\n",
    "# I Will select \"cnt\" as target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8d09a7",
   "metadata": {},
   "source": [
    "# 1- Exploratory Data Analysis\n",
    "- What is the distribution of the number of rented bicycles throughout the day?\n",
    "- Does the season, holiday, or weekday affect the number of bikes rented?\n",
    "- Do temperature, humidity, and wind affect the number of bicycles rented?\n",
    "- Is there a connection between the columns?\n",
    "- Are there any outliers that might affect the analysis or modeling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7390aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad7d340",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(variables='real_season')\n",
    "ohe.fit_transform(df).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0befd94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.real_season.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636e87dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# What is the distribution of the number of rented bicycles throughout the day?\n",
    "# 1) Distribution of rentals throughout the day\n",
    "hourly = df.groupby('hr')['cnt'].median()\n",
    "sns.lineplot(x=hourly.index, y=hourly.values, ax=axes[0, 0])\n",
    "axes[0, 0].set_title(\"Average Number of Rentals Throughout the Day\")\n",
    "axes[0, 0].set_xlabel(\"Hour of Day\")\n",
    "axes[0, 0].set_ylabel(\"Median Rentals\")\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Does the season, holiday, or weekday affect the number of bikes rented?\n",
    "# 2) Rentals by Season\n",
    "season_order = ['spring', 'summer', 'fall', 'winter']\n",
    "seasonal = df.groupby('real_season')['cnt'].median()\n",
    "sns.barplot(x=seasonal.index, y=seasonal.values, order=season_order, ax=axes[0, 1])\n",
    "axes[0, 1].set_title(\"Average Rentals by Season\")\n",
    "axes[0, 1].set_xlabel(\"Season\")\n",
    "axes[0, 1].set_ylabel(\"Median Rentals\")\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# 3) Rentals on Holidays vs Non-Holidays\n",
    "holiday = df.groupby('holiday')['cnt'].median()\n",
    "sns.barplot(x=holiday.index, y=holiday.values, ax=axes[1, 0])\n",
    "axes[1, 0].set_title(\"Median Rentals on Holidays\")\n",
    "axes[1, 0].set_xlabel(\"Holiday (0=No, 1=Yes)\")\n",
    "axes[1, 0].set_ylabel(\"Median Rentals\")\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# 4) Rentals by Weekday\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "weekday = df.groupby('weekday_name')['cnt'].median()\n",
    "sns.barplot(x=weekday.index, y=weekday.values, order=day_order, ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Median Rentals by Weekday\")\n",
    "axes[1, 1].set_xlabel(\"Weekday\")\n",
    "axes[1, 1].set_ylabel(\"Median Rentals\")\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa01273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['season', 'holiday', 'weekday', 'workingday', 'weathersit']\n",
    "num_cols = ['mnth', 'hr', 'temp', 'atemp', 'hum', 'windspeed',\n",
    "            'casual', 'registered', 'cnt']\n",
    "\n",
    "num_cols2 = num_cols.copy()\n",
    "num_cols2.remove('casual'); num_cols2.remove('registered')\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(22, 6)\n",
    "                         )\n",
    "# Do temperature, humidity, and wind affect the number of bicycles rented?\n",
    "# Correlation: temp, atemp, hum, windspeed vs cnt\n",
    "affect_corr = df[['temp', 'atemp', 'hum', 'windspeed', 'cnt']].corr()\n",
    "affect_mask = np.triu(np.ones_like(affect_corr, dtype=bool))\n",
    "sns.heatmap(affect_corr, annot=True, mask=affect_mask, ax=axes[0])\n",
    "axes[0].set_title('Correlation: temp / hum / wind vs cnt')\n",
    "\n",
    "# Is there a connection between the columns\n",
    "# Correlation: all numerical columns \n",
    "corr = df[num_cols2].corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "sns.heatmap(corr, annot=True, mask=mask, ax=axes[1])\n",
    "axes[1].set_title(\"Correlation between numeric features\")\n",
    "\n",
    "# Are there any outliers that might affect the analysis or modeling?\n",
    "# Boxplot: Outliers\n",
    "df[['real_temp', 'real_atemp', 'real_hum', 'real_windspeed']].plot(\n",
    "    kind='box', ax=axes[2]\n",
    ")\n",
    "axes[2].set_title(\"Checking for outliers\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef5ff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming columns with outliers (log(1 + x))\n",
    "# df['log_casual'] = np.log1p(df['casual'])      # log(1 + x)\n",
    "df['log_registered'] = np.log1p(df['registered'])\n",
    "df['log_real_windspeed'] = np.log1p(df['real_windspeed'])\n",
    "df['log_casual'] = np.log1p(df['casual'])\n",
    "\n",
    "df[['log_registered', 'log_real_windspeed']].plot(kind='box')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad30a6",
   "metadata": {},
   "source": [
    "## 2- Time-Series / Temporal Analysis\n",
    "- How does the number of bicycles change over the course of an hour, day, or month?\n",
    "- Is there any clear trend or seasonality?\n",
    "- Is there any difference between weekdays and weekends?\n",
    "- Is data needs scaling or smoothing before modeling?\n",
    "* Official holidays are (Saturday, Sunday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c739137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the number of bicycles change over the course of an hour, day, or month?\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 9))\n",
    "MEAN = 'mean'\n",
    "MEDIAN = 'median'\n",
    "\n",
    "# Rush Hours\n",
    "rush_hours = df.groupby('hr', as_index=False).agg(mean_rented_bikes=('cnt', MEDIAN))\n",
    "sns.barplot(data=rush_hours, x='hr', y='mean_rented_bikes', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Median number of rented bikes per Hour')\n",
    "axes[0, 0].set_ylabel(\"Average Bikes Number\")\n",
    "axes[0, 0].set_xlabel(\"Hour\")\n",
    "\n",
    "# Rush Days\n",
    "rush_day = df.groupby('weekday_name', as_index=False).agg(mean_rented_bikes=('cnt', MEDIAN))\n",
    "sns.barplot(data=rush_day, x='weekday_name', y='mean_rented_bikes', order=day_order, ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Median number of rented bikes per Day')\n",
    "axes[0, 1].set_ylabel(\"Average Bikes Number\")\n",
    "axes[0, 1].set_xlabel(\"Day\")\n",
    "\n",
    "# Rush Months\n",
    "month_order = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "rush_month = df.groupby('month_name', as_index=False).agg(mean_rented_bikes=('cnt', MEDIAN))\n",
    "sns.barplot(data=rush_month, x='month_name', y='mean_rented_bikes', order=month_order, ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Median number of rented bikes per Month')\n",
    "axes[1, 0].set_ylabel(\"Average Bikes Number\")\n",
    "axes[1, 0].set_xlabel(\"Month\")\n",
    "\n",
    "\n",
    "# Is there any clear trend or seasonality?\n",
    "rush_season = df.groupby('real_season', as_index=False).agg(mean_rented_bikes=('cnt', MEDIAN))\n",
    "sns.barplot(data=rush_season, x='real_season', y='mean_rented_bikes', order=season_order, ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Median number of rented bikes per Season')\n",
    "axes[1, 1].set_ylabel(\"Average Bikes Number\")\n",
    "axes[1, 1].set_xlabel(\"Season\")\n",
    "\n",
    "\n",
    "# Is there any difference between weekdays and weekends?\n",
    "# Mean rented bikes for working days vs non-working days\n",
    "df.groupby('workday_or_holiday', as_index=False)['cnt'].median() \\\n",
    "  .rename(columns={'workday_or_holiday': 'is_working_day', 'cnt': 'mean_rented_bikes'}).plot(kind='bar', x='is_working_day', y='mean_rented_bikes', ax=axes[2, 0], legend=False)\n",
    "axes[2, 0].set_title(\"Defference between rented bikes in Weekdays VS (Weekends & Holidays)\")\n",
    "axes[2, 0].set_xlabel('')\n",
    "axes[2, 0].set_ylabel('')\n",
    "axes[2, 0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "\n",
    "# Hide last empty subplot\n",
    "axes[2, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Is data needs scaling or smoothing before modeling?\n",
    "# Not realy because it normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243cf0f5",
   "metadata": {},
   "source": [
    "## 3- Advanced Insights\n",
    "- Is `Casual`, `Registered` Users have different behavior?\n",
    "- What factors affect on `casual` vs `registered` Users?\n",
    "- What is the best feature predictor number of bicycles to rent?\n",
    "- Can we create a new feature to help the model? (is_weekend, rush_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4997f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def melting_casual_registered(col:str): # Using (mean)\n",
    "    rush_feature = df.groupby(col)[['casual', 'registered']].mean().reset_index()\n",
    "\n",
    "    # melt to make hue work\n",
    "    rush_melt = rush_feature.melt(id_vars=col,\n",
    "                                    value_vars=['casual', 'registered'],\n",
    "                                    var_name='user_type',\n",
    "                                    value_name='median_rented_bikes')\n",
    "    return rush_melt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dd7a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is `Casual`, `Registered` Users have different behavior?\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(20, 10))\n",
    "\n",
    "# Function already defined by you:\n",
    "# melting_casual_registered(col)\n",
    "\n",
    "# Hour \n",
    "rush_hours_melt = melting_casual_registered('hr')\n",
    "sns.barplot(\n",
    "    data=rush_hours_melt,\n",
    "    x='hr',\n",
    "    y='median_rented_bikes',\n",
    "    hue='user_type',\n",
    "    ax=axes[0, 0]\n",
    ")\n",
    "axes[0, 0].set_title('Casual vs Registered — Median bikes per Hour')\n",
    "axes[0, 0].set_xlabel('Hour')\n",
    "axes[0, 0].set_ylabel('Median Bikes')\n",
    "\n",
    "# Weekday Name\n",
    "rush_weekdayname_melt = melting_casual_registered('weekday_name')\n",
    "sns.barplot(\n",
    "    data=rush_weekdayname_melt,\n",
    "    x='weekday_name',\n",
    "    y='median_rented_bikes',\n",
    "    hue='user_type',\n",
    "    order=day_order,\n",
    "    ax=axes[0, 1]\n",
    ")\n",
    "axes[0, 1].set_title('Casual vs Registered — Median per Day')\n",
    "axes[0, 1].set_xlabel('Day')\n",
    "axes[0, 1].set_ylabel('Median Bikes')\n",
    "\n",
    "# Month Name \n",
    "rush_month_melt = melting_casual_registered('month_name')\n",
    "sns.barplot(\n",
    "    data=rush_month_melt,\n",
    "    x='month_name',\n",
    "    y='median_rented_bikes',\n",
    "    hue='user_type',\n",
    "    order=month_order,\n",
    "    ax=axes[1, 0]\n",
    ")\n",
    "axes[1, 0].set_title('Casual vs Registered — Median per Month')\n",
    "axes[1, 0].set_xlabel('Month')\n",
    "axes[1, 0].set_ylabel('Median Bikes')\n",
    "\n",
    "# Season \n",
    "rush_season_melt = melting_casual_registered('real_season')\n",
    "sns.barplot(\n",
    "    data=rush_season_melt,\n",
    "    x='real_season',\n",
    "    y='median_rented_bikes',\n",
    "    hue='user_type',\n",
    "    order=season_order,\n",
    "    ax=axes[1, 1]\n",
    ")\n",
    "axes[1, 1].set_title('Casual vs Registered — Median per Season')\n",
    "axes[1, 1].set_xlabel('Season')\n",
    "axes[1, 1].set_ylabel('Median Bikes')\n",
    "\n",
    "# Working Day vs Holiday ---\n",
    "rush_workday_melt = melting_casual_registered('workday_or_holiday')\n",
    "sns.barplot(\n",
    "    data=rush_workday_melt,\n",
    "    x='workday_or_holiday',\n",
    "    y='median_rented_bikes',\n",
    "    hue='user_type',\n",
    "    ax=axes[2, 0]\n",
    ")\n",
    "axes[2, 0].set_title(\"Casual vs Registered — Workingday vs (Holiday & Weekend)\")\n",
    "axes[2, 0].set_xlabel(\"Workday (1) | Weekend/Holiday (0)\")\n",
    "axes[2, 0].set_ylabel(\"Median Bikes\")\n",
    "\n",
    "# Hide last empty subplot\n",
    "axes[2, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b23b2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What factors affect on `casual` vs `registered` Users?\n",
    "casual_users = num_cols.copy()\n",
    "casual_users.remove('cnt'); casual_users.remove('registered')\n",
    "\n",
    "registered_users = num_cols.copy()\n",
    "registered_users.remove('cnt'); registered_users.remove('casual')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(22, 6))\n",
    "\n",
    "# Correlation for Casual Users\n",
    "affect_casual_corr = df[casual_users].corr()\n",
    "affect_casual_mask = np.triu(np.ones_like(affect_casual_corr, dtype=bool))\n",
    "sns.heatmap(affect_casual_corr, annot=True, mask=affect_casual_mask, ax=axes[0])\n",
    "axes[0].set_title('Correlation between features affecting Casual Users')\n",
    "\n",
    "# Correlation for Registered Users\n",
    "affect_registered_corr = df[registered_users].corr()\n",
    "affect_registered_mask = np.triu(np.ones_like(affect_registered_corr, dtype=bool))\n",
    "sns.heatmap(affect_registered_corr, annot=True, mask=affect_registered_mask, ax=axes[1])\n",
    "axes[1].set_title('Correlation between features affecting Registered Users')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# We can see that [hr, temp, atemp] have a positive relation with (casual, registered) users\n",
    "# And [hum] have a negative relation with (casual, registered) users\n",
    "\n",
    "# Can we create a new feature to help the model? (is_weekend, rush_hour)\n",
    "# there is two columns (holiday & workingday) that can replace is_weekend\n",
    "# So I can create a column that tells me if it is a rush hour or not for either (casual or registered) Users\n",
    "\n",
    "# IS Rush hours for Registered Users\n",
    "\n",
    "registered_rush_hrs = df.groupby('hr', as_index=False)['registered'].sum().sort_values('registered',ascending=False)['hr'].head().tolist()\n",
    "df['registered_rush_hrs'] = df['hr'].isin(registered_rush_hrs).astype(int)\n",
    "\n",
    "\n",
    "# IS Rush hours for Casual Users\n",
    "casual_rush_hrs = df.groupby('hr', as_index=False)['casual'].sum().sort_values('casual',ascending=False)['hr'].head().tolist()\n",
    "df['casual_rush_hrs'] = df['hr'].isin(casual_rush_hrs).astype(int)\n",
    "\n",
    "# IS Rush hours for all users\n",
    "cnt_rush_hrs = df.groupby('hr', as_index=False)['cnt'].sum().sort_values('cnt',ascending=False)['hr'].head().tolist()\n",
    "df['cnt_rush_hrs'] = df['hr'].isin(registered_rush_hrs).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7989d8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What factors affect on `casual` vs `registered` Users?\n",
    "casual_users = num_cols.copy()\n",
    "casual_users.remove('cnt'); casual_users.remove('registered'); casual_users.append('casual_rush_hrs')\n",
    "\n",
    "registered_users = num_cols.copy()\n",
    "registered_users.remove('cnt'); registered_users.remove('casual'); registered_users.append('registered_rush_hrs')\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(22, 6))\n",
    "\n",
    "# Correlation for Casual Users\n",
    "affect_casual_corr = df[casual_users].corr()\n",
    "affect_casual_mask = np.triu(np.ones_like(affect_casual_corr, dtype=bool))\n",
    "sns.heatmap(affect_casual_corr, annot=True, mask=affect_casual_mask, ax=axes[0])\n",
    "axes[0].set_title('Correlation between features affecting Casual Users')\n",
    "\n",
    "# Correlation for Registered Users\n",
    "affect_registered_corr = df[registered_users].corr()\n",
    "affect_registered_mask = np.triu(np.ones_like(affect_registered_corr, dtype=bool))\n",
    "sns.heatmap(affect_registered_corr, annot=True, mask=affect_registered_mask, ax=axes[1])\n",
    "axes[1].set_title('Correlation between features affecting Registered Users')\n",
    "\n",
    "# Correlation for all Users\n",
    "num_cols.append('cnt_rush_hrs')\n",
    "all_users_num_cols = num_cols.copy(); all_users_num_cols.remove('casual'); all_users_num_cols.remove('registered')\n",
    "affect_user_corr = df[all_users_num_cols].corr()\n",
    "affect_user_mask = np.triu(np.ones_like(affect_user_corr, dtype=bool))\n",
    "sns.heatmap(affect_user_corr, annot=True, mask=affect_user_mask, ax=axes[2])\n",
    "axes[2].set_title('Correlation between features affecting All Users')\n",
    "axes[2].tick_params(axis='y', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33605bcf",
   "metadata": {},
   "source": [
    "## 4- Understanding the relationship between categorical columns\n",
    "- Using Chi-Square test to know if there is a relationship or not\n",
    "- Then Using Cramers_v to determine the strength of the relationship between the category columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312649d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "cat_cols = ['season', 'holiday', 'weekday', 'workingday', 'weathersit']\n",
    "\n",
    "chi2_pvals = pd.DataFrame(index=cat_cols, columns=cat_cols)\n",
    "\n",
    "for col1 in cat_cols:\n",
    "    for col2 in cat_cols:\n",
    "        if col1 == col2:\n",
    "            chi2_pvals.loc[col1, col2] = 1.0 \n",
    "        else:\n",
    "            contingency = pd.crosstab(df[col1], df[col2])\n",
    "            chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "            chi2_pvals.loc[col1, col2] = p\n",
    "\n",
    "chi2_pvals = chi2_pvals.astype(float)\n",
    "\n",
    "print(\"Chi-square p-values matrix for categorical columns:\")\n",
    "display(chi2_pvals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a8fe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(\n",
    "    chi2_pvals,\n",
    "    annot=True,\n",
    "    fmt=\".4f\",\n",
    "    # cmap=\"coolwarm_r\",  \n",
    "    cbar_kws={'label': 'p-value'}\n",
    ")\n",
    "plt.title(\"Chi-square P-values Heatmap for Categorical Columns\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17047d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cramers_v(x, y):\n",
    "    confusion_matrix = pd.crosstab(x, y)\n",
    "    chi2 = chi2_contingency(confusion_matrix)[0]  \n",
    "    n = confusion_matrix.sum().sum()              \n",
    "    r, k = confusion_matrix.shape                 \n",
    "    return np.sqrt(chi2 / (n * (min(r, k) - 1)))\n",
    "\n",
    "cat_cols = ['season', 'holiday', 'weekday', 'workingday', 'weathersit']\n",
    "\n",
    "for i, col1 in enumerate(cat_cols):\n",
    "    for col2 in cat_cols[i+1:]:\n",
    "        v = cramers_v(df[col1], df[col2])\n",
    "        print(f\"Cramér's V between {col1} and {col2}: {v:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdf3c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "df_daily = df.groupby('dteday')['cnt'].sum()\n",
    "\n",
    "result = seasonal_decompose(df_daily, model='additive', period=30)\n",
    "result.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03df5a7c",
   "metadata": {},
   "source": [
    "## 5- Modeling\n",
    "### `Note: That you have to split data to train and test dataframes, Before Selecting features for your model to not cause a data leakage`\n",
    "- What type of model do you think is suitable for predicting the number of bicycles? [Time Series, Regression, ML model]\n",
    "- What matrix will you use to measure the model's performance? [R2_score, MAE, RMSE]\n",
    "- If there is overfitting, how will you fix it?\n",
    "- Do you need to do cross-validation? If so, how?\n",
    "\n",
    "    * Regression model\n",
    "    * feature Engineering\n",
    "    * Feature Importance\n",
    "    * Time series Trend / Seasonal Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90006a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 323\n",
      "[LightGBM] [Info] Number of data points in the train set: 13903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 174.639143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from feature_engine.creation import CyclicalFeatures\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import optuna\n",
    "from optuna.integration import OptunaSearchCV\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error, mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "cols = ['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday',\n",
    "       'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed',\n",
    "       'cnt']\n",
    "\n",
    "X = df[cols].drop(labels='cnt', axis=1)\n",
    "y = df['cnt']\n",
    "\n",
    "class RushHourTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables: list[str], target: str = \"cnt\", top_n: int = 5):\n",
    "        self.variables = variables\n",
    "        self.target = target\n",
    "        self.top_n = top_n\n",
    "        self.top_hours_ = {}\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series = None):\n",
    "        if y is None:\n",
    "            raise ValueError(\"y must be provided for RushHourTransformer fit\")\n",
    "\n",
    "        for var in self.variables:\n",
    "            temp_df = pd.DataFrame({var: X[var], self.target: y})\n",
    "            top_hours = (\n",
    "                temp_df.groupby(var)[self.target]\n",
    "                .sum()\n",
    "                .sort_values(ascending=False)\n",
    "                .head(self.top_n)\n",
    "                .index.tolist()\n",
    "            )\n",
    "            self.top_hours_[var] = top_hours\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame, y=None):\n",
    "        X_transformed = X.copy()\n",
    "        for var in self.variables:\n",
    "            X_transformed[f\"{var}_rush_hr\"] = (\n",
    "                X_transformed[var].isin(self.top_hours_[var]).astype(int)\n",
    "            )\n",
    "        return X_transformed\n",
    "\n",
    "\n",
    "# Not Shuffling beacause it's a datetime data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, shuffle=False, random_state=42)\n",
    "\n",
    "# Splitting training columns to it's type\n",
    "cyclical_cols = ['season', 'mnth', 'weekday', 'hr']\n",
    "binary_cols = ['yr', 'holiday', 'workingday']\n",
    "new_feat = [] # 'casual', 'registered'\n",
    "num_cols = ['temp', 'atemp', 'hum', 'windspeed']\n",
    "cat_cols = ['weathersit']\n",
    "\n",
    "# Making pipe lines for each type of columns \n",
    "cyclical_pipe = Pipeline(steps=[\n",
    "    ('cyclical_transformation', CyclicalFeatures(drop_original=True))\n",
    "])\n",
    "\n",
    "numeric_pipe = Pipeline(steps=[\n",
    "    ('scalling_numbers', StandardScaler())\n",
    "])\n",
    "\n",
    "categories_pipe = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder(sparse_output=False))\n",
    "])\n",
    "\n",
    "# Specifing list of columns for each transfromer\n",
    "ct = ColumnTransformer(transformers=[\n",
    "    ('cyclical', cyclical_pipe, cyclical_cols),\n",
    "    ('scalling', numeric_pipe, num_cols),\n",
    "    ('ohe', categories_pipe, cat_cols)\n",
    "    ],\n",
    "    remainder='drop').set_output(transform='pandas')\n",
    "\n",
    "# Making a functiontransformer to get rush hours for (casual, registered)\n",
    "# rush_transformer = FunctionTransformer(RushHourTransformer(variables=['hr']), validate=False)\n",
    "    \n",
    "def compare_between_models(models: dict):\n",
    "    \"\"\"Fucntion to make a comparing between ML models\"\"\"\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for model_name, model_obj in models.items():\n",
    "\n",
    "        full_pipeline = Pipeline(steps=[\n",
    "            ('rush_hrs', RushHourTransformer(variables=[\"hr\"], target=\"cnt\", top_n=5)),\n",
    "            ('preprocessing', ct),\n",
    "            ('model', model_obj)\n",
    "        ])\n",
    "\n",
    "        # Trian\n",
    "        full_pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_pred_train = full_pipeline.predict(X_train)\n",
    "        y_pred_test = full_pipeline.predict(X_test)\n",
    "\n",
    "        # Store metrics\n",
    "        results[model_name] = {\n",
    "            \"r2_train\": r2_score(y_train, y_pred_train),\n",
    "            \"r2_test\": r2_score(y_test, y_pred_test),\n",
    "            \"rmse_train\": root_mean_squared_error(y_train, y_pred_train),\n",
    "            \"rmse_test\": root_mean_squared_error(y_test, y_pred_test),\n",
    "            \"mae_train\": mean_absolute_error(y_train, y_pred_train),\n",
    "            \"mae_test\": mean_absolute_error(y_test, y_pred_test)\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "models = {'XGBRegressor': XGBRegressor(),\n",
    "          'CatBoostRegressor': CatBoostRegressor(verbose=0),\n",
    "          'LGBMRegressor': LGBMRegressor()}\n",
    "\n",
    "models_comparing_result = pd.DataFrame(compare_between_models(models=models))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87c13768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBRegressor</th>\n",
       "      <th>CatBoostRegressor</th>\n",
       "      <th>LGBMRegressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2_train</th>\n",
       "      <td>0.946035</td>\n",
       "      <td>0.925754</td>\n",
       "      <td>0.903382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test</th>\n",
       "      <td>0.673023</td>\n",
       "      <td>0.679482</td>\n",
       "      <td>0.670417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_train</th>\n",
       "      <td>38.783062</td>\n",
       "      <td>45.490505</td>\n",
       "      <td>51.893581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_test</th>\n",
       "      <td>126.077324</td>\n",
       "      <td>124.825944</td>\n",
       "      <td>126.578796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae_train</th>\n",
       "      <td>25.809240</td>\n",
       "      <td>30.426882</td>\n",
       "      <td>34.918496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae_test</th>\n",
       "      <td>89.116280</td>\n",
       "      <td>89.290588</td>\n",
       "      <td>90.154502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            XGBRegressor  CatBoostRegressor  LGBMRegressor\n",
       "r2_train        0.946035           0.925754       0.903382\n",
       "r2_test         0.673023           0.679482       0.670417\n",
       "rmse_train     38.783062          45.490505      51.893581\n",
       "rmse_test     126.077324         124.825944     126.578796\n",
       "mae_train      25.809240          30.426882      34.918496\n",
       "mae_test       89.116280          89.290588      90.154502"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_comparing_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96625e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamter Optimization using GridSearchCV\n",
    "\n",
    "# Base CatBoost model\n",
    "cat_model = CatBoostRegressor(\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Full pipeline\n",
    "full_pipeline = Pipeline(steps=[\n",
    "    ('rush_hrs', rush_transformer),\n",
    "    ('preprocessing', ct),\n",
    "    ('model', cat_model)\n",
    "])\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'model__iterations': [500, 1000],       \n",
    "    'model__depth': [4, 6, 8],              \n",
    "    'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'model__l2_leaf_reg': [1, 3, 5]         \n",
    "}\n",
    "\n",
    "# GridSearchCV \n",
    "grid_search = GridSearchCV(\n",
    "    estimator=full_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,                    \n",
    "    scoring='r2',      \n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Train \n",
    "print(\"GridSearchCV Searching for Best HyperParameters ...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best Modle\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# train & test\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "results = {\n",
    "    \"r2_train\": r2_score(y_train, y_pred_train),\n",
    "    \"r2_test\": r2_score(y_test, y_pred_test),\n",
    "    \"rmse_train\": root_mean_squared_error(y_train, y_pred_train),\n",
    "    \"rmse_test\": root_mean_squared_error(y_test, y_pred_test),\n",
    "    \"mae_train\": mean_absolute_error(y_train, y_pred_train),\n",
    "    \"mae_test\": mean_absolute_error(y_test, y_pred_test)\n",
    "}\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7ec7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamter Optimization using Optuna\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "# Base CatBoost model \n",
    "cat_model = CatBoostRegressor(\n",
    "    verbose=0,\n",
    "    random_state=42,\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "# Full pipeline \n",
    "full_pipeline = Pipeline(steps=[\n",
    "    ('rush_hrs', rush_transformer),\n",
    "    ('preprocessing', ct),\n",
    "    ('model', cat_model)\n",
    "])\n",
    "\n",
    "# Define parameter search space \n",
    "param_distributions = {\n",
    "    'model__iterations': optuna.distributions.IntDistribution(500, 1500),\n",
    "    'model__depth': optuna.distributions.IntDistribution(4, 10),\n",
    "    'model__learning_rate': optuna.distributions.FloatDistribution(0.01, 0.2, log=True),\n",
    "    'model__l2_leaf_reg': optuna.distributions.FloatDistribution(1, 10)\n",
    "}\n",
    "\n",
    "# Optuna Search \n",
    "optuna_search = OptunaSearchCV(\n",
    "    estimator=full_pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    cv=3,\n",
    "    scoring='r2',\n",
    "    n_trials=30, \n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train \n",
    "print(\"Optuna Searching for Best HyperParamters ...\")\n",
    "optuna_search.fit(X_train, y_train)\n",
    "\n",
    "# Best Model\n",
    "best_model = optuna_search.best_estimator_\n",
    "print(\"Best Parameters:\", optuna_search.best_params_)\n",
    "\n",
    "# train & test \n",
    "y_pred_train = best_model.predict(X_train)\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "results = {\n",
    "    \"r2_train\": r2_score(y_train, y_pred_train),\n",
    "    \"r2_test\": r2_score(y_test, y_pred_test),\n",
    "    \"rmse_train\": root_mean_squared_error(y_train, y_pred_train),\n",
    "    \"rmse_test\": root_mean_squared_error(y_test, y_pred_test),\n",
    "    \"mae_train\": mean_absolute_error(y_train, y_pred_train),\n",
    "    \"mae_test\": mean_absolute_error(y_test, y_pred_test)\n",
    "}\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fa980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparing_df = pd.DataFrame(models_comparing_result)\n",
    "comparing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c12bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparing_df_t = comparing_df.T\n",
    "models = comparing_df_t.index.tolist()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# R2 Test\n",
    "axes[0].bar(models, comparing_df_t[\"r2_test\"])\n",
    "axes[0].set_title(\"R2 (Test)\")\n",
    "axes[0].set_ylabel(\"R2 (higher is better)\")\n",
    "axes[0].set_ylim(0, 1.05)\n",
    "axes[0].grid(axis='y', linestyle='--', alpha=0.3)\n",
    "axes[0].tick_params(axis='x', rotation=15)\n",
    "\n",
    "# RMSE Test\n",
    "axes[1].bar(models, comparing_df_t[\"rmse_test\"])\n",
    "axes[1].set_title(\"RMSE (Test)\")\n",
    "axes[1].set_ylabel(\"RMSE (lower is better)\")\n",
    "axes[1].grid(axis='y', linestyle='--', alpha=0.3)\n",
    "axes[1].tick_params(axis='x', rotation=15)\n",
    "\n",
    "# MAE Test\n",
    "axes[2].bar(models, comparing_df_t[\"mae_test\"])\n",
    "axes[2].set_title(\"MAE (Test)\")\n",
    "axes[2].set_ylabel(\"MAE (lower is better)\")\n",
    "axes[2].grid(axis='y', linestyle='--', alpha=0.3)\n",
    "axes[2].tick_params(axis='x', rotation=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eca473",
   "metadata": {},
   "source": [
    "So We can see that\n",
    "* CatBoostRegressor is the best base model \n",
    "* Next step is to make a Hyperparameter optimization for it\n",
    "* Then Saving model and It's Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747fbe33",
   "metadata": {},
   "source": [
    "## 6- Recommendation / Insights\n",
    "- What are the most important factors that influence bicycle usage?\n",
    "- If we were a bike-sharing company, what steps could we take based on this analysis?\n",
    "- What is the best time to increase the number of bicycles at stations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4695bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
